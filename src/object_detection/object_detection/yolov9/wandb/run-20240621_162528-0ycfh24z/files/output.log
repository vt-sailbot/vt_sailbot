Overriding model.yaml nc=80 with nc=1
                 from  n    params  module                                  arguments
  0                -1  1         0  models.common.Silence                   []
  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]
  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  3                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]
  4                -1  1    164352  models.common.ADown                     [256, 256]
  5                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]
  6                -1  1    656384  models.common.ADown                     [512, 512]
  7                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]
  8                -1  1    656384  models.common.ADown                     [512, 512]
  9                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]
 10                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 7]  1         0  models.common.Concat                    [1]
 13                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]
 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 15           [-1, 5]  1         0  models.common.Concat                    [1]
 16                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]
 17                -1  1    164352  models.common.ADown                     [256, 256]
 18          [-1, 13]  1         0  models.common.Concat                    [1]
 19                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]
 20                -1  1    656384  models.common.ADown                     [512, 512]
 21          [-1, 10]  1         0  models.common.Concat                    [1]
 22                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]
 23                 5  1    131328  models.common.CBLinear                  [512, [256]]
 24                 7  1    393984  models.common.CBLinear                  [512, [256, 512]]
 25                 9  1    656640  models.common.CBLinear                  [512, [256, 512, 512]]
 26                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]
 27                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
 28                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]
 29                -1  1    164352  models.common.ADown                     [256, 256]
 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]
 31                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]
 32                -1  1    656384  models.common.ADown                     [512, 512]
 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]
 34                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]
 35                -1  1    656384  models.common.ADown                     [512, 512]
 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]
 37                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]
 38[31, 34, 37, 16, 19, 22]  1  21542822  models.yolo.DualDDetect                 [1, [512, 512, 512, 256, 512, 512]]
yolov9-c summary: 962 layers, 50999590 parameters, 50999558 gradients, 238.9 GFLOPs
Transferred 1448/1460 items from weights/yolov9-c.pt
[34m[1mAMP: [39m[22mchecks passed âœ…
freezing model.1.conv.weight
freezing model.1.bn.weight
freezing model.1.bn.bias
freezing model.2.conv.weight
freezing model.2.bn.weight
freezing model.2.bn.bias
freezing model.3.cv1.conv.weight
freezing model.3.cv1.bn.weight
freezing model.3.cv1.bn.bias
freezing model.3.cv2.0.cv1.conv.weight
freezing model.3.cv2.0.cv1.bn.weight
freezing model.3.cv2.0.cv1.bn.bias
freezing model.3.cv2.0.cv2.conv.weight
freezing model.3.cv2.0.cv2.bn.weight
freezing model.3.cv2.0.cv2.bn.bias
freezing model.3.cv2.0.cv3.conv.weight
freezing model.3.cv2.0.cv3.bn.weight
freezing model.3.cv2.0.cv3.bn.bias
freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.3.cv2.0.m.0.cv2.conv.weight
freezing model.3.cv2.0.m.0.cv2.bn.weight
freezing model.3.cv2.0.m.0.cv2.bn.bias
freezing model.3.cv2.1.conv.weight
freezing model.3.cv2.1.bn.weight
freezing model.3.cv2.1.bn.bias
freezing model.3.cv3.0.cv1.conv.weight
freezing model.3.cv3.0.cv1.bn.weight
freezing model.3.cv3.0.cv1.bn.bias
freezing model.3.cv3.0.cv2.conv.weight
freezing model.3.cv3.0.cv2.bn.weight
freezing model.3.cv3.0.cv2.bn.bias
freezing model.3.cv3.0.cv3.conv.weight
freezing model.3.cv3.0.cv3.bn.weight
freezing model.3.cv3.0.cv3.bn.bias
freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.3.cv3.0.m.0.cv2.conv.weight
freezing model.3.cv3.0.m.0.cv2.bn.weight
freezing model.3.cv3.0.m.0.cv2.bn.bias
freezing model.3.cv3.1.conv.weight
freezing model.3.cv3.1.bn.weight
freezing model.3.cv3.1.bn.bias
freezing model.3.cv4.conv.weight
freezing model.3.cv4.bn.weight
freezing model.3.cv4.bn.bias
freezing model.4.cv1.conv.weight
freezing model.4.cv1.bn.weight
freezing model.4.cv1.bn.bias
freezing model.4.cv2.conv.weight
freezing model.4.cv2.bn.weight
freezing model.4.cv2.bn.bias
freezing model.5.cv1.conv.weight
freezing model.5.cv1.bn.weight
freezing model.5.cv1.bn.bias
freezing model.5.cv2.0.cv1.conv.weight
freezing model.5.cv2.0.cv1.bn.weight
freezing model.5.cv2.0.cv1.bn.bias
freezing model.5.cv2.0.cv2.conv.weight
freezing model.5.cv2.0.cv2.bn.weight
freezing model.5.cv2.0.cv2.bn.bias
freezing model.5.cv2.0.cv3.conv.weight
freezing model.5.cv2.0.cv3.bn.weight
freezing model.5.cv2.0.cv3.bn.bias
freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.5.cv2.0.m.0.cv2.conv.weight
freezing model.5.cv2.0.m.0.cv2.bn.weight
freezing model.5.cv2.0.m.0.cv2.bn.bias
freezing model.5.cv2.1.conv.weight
freezing model.5.cv2.1.bn.weight
freezing model.5.cv2.1.bn.bias
freezing model.5.cv3.0.cv1.conv.weight
freezing model.5.cv3.0.cv1.bn.weight
freezing model.5.cv3.0.cv1.bn.bias
freezing model.5.cv3.0.cv2.conv.weight
freezing model.5.cv3.0.cv2.bn.weight
freezing model.5.cv3.0.cv2.bn.bias
freezing model.5.cv3.0.cv3.conv.weight
freezing model.5.cv3.0.cv3.bn.weight
freezing model.5.cv3.0.cv3.bn.bias
freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.5.cv3.0.m.0.cv2.conv.weight
freezing model.5.cv3.0.m.0.cv2.bn.weight
freezing model.5.cv3.0.m.0.cv2.bn.bias
freezing model.5.cv3.1.conv.weight
freezing model.5.cv3.1.bn.weight
freezing model.5.cv3.1.bn.bias
freezing model.5.cv4.conv.weight
freezing model.5.cv4.bn.weight
freezing model.5.cv4.bn.bias
freezing model.6.cv1.conv.weight
freezing model.6.cv1.bn.weight
freezing model.6.cv1.bn.bias
freezing model.6.cv2.conv.weight
freezing model.6.cv2.bn.weight
freezing model.6.cv2.bn.bias
freezing model.7.cv1.conv.weight
freezing model.7.cv1.bn.weight
freezing model.7.cv1.bn.bias
freezing model.7.cv2.0.cv1.conv.weight
freezing model.7.cv2.0.cv1.bn.weight
freezing model.7.cv2.0.cv1.bn.bias
freezing model.7.cv2.0.cv2.conv.weight
freezing model.7.cv2.0.cv2.bn.weight
freezing model.7.cv2.0.cv2.bn.bias
freezing model.7.cv2.0.cv3.conv.weight
freezing model.7.cv2.0.cv3.bn.weight
freezing model.7.cv2.0.cv3.bn.bias
freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.7.cv2.0.m.0.cv2.conv.weight
freezing model.7.cv2.0.m.0.cv2.bn.weight
freezing model.7.cv2.0.m.0.cv2.bn.bias
freezing model.7.cv2.1.conv.weight
freezing model.7.cv2.1.bn.weight
freezing model.7.cv2.1.bn.bias
freezing model.7.cv3.0.cv1.conv.weight
freezing model.7.cv3.0.cv1.bn.weight
freezing model.7.cv3.0.cv1.bn.bias
freezing model.7.cv3.0.cv2.conv.weight
freezing model.7.cv3.0.cv2.bn.weight
freezing model.7.cv3.0.cv2.bn.bias
freezing model.7.cv3.0.cv3.conv.weight
freezing model.7.cv3.0.cv3.bn.weight
freezing model.7.cv3.0.cv3.bn.bias
freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.7.cv3.0.m.0.cv2.conv.weight
freezing model.7.cv3.0.m.0.cv2.bn.weight
freezing model.7.cv3.0.m.0.cv2.bn.bias
freezing model.7.cv3.1.conv.weight
freezing model.7.cv3.1.bn.weight
freezing model.7.cv3.1.bn.bias
freezing model.7.cv4.conv.weight
freezing model.7.cv4.bn.weight
freezing model.7.cv4.bn.bias
freezing model.8.cv1.conv.weight
freezing model.8.cv1.bn.weight
freezing model.8.cv1.bn.bias
freezing model.8.cv2.conv.weight
freezing model.8.cv2.bn.weight
freezing model.8.cv2.bn.bias
freezing model.9.cv1.conv.weight
freezing model.9.cv1.bn.weight
freezing model.9.cv1.bn.bias
freezing model.9.cv2.0.cv1.conv.weight
freezing model.9.cv2.0.cv1.bn.weight
freezing model.9.cv2.0.cv1.bn.bias
freezing model.9.cv2.0.cv2.conv.weight
freezing model.9.cv2.0.cv2.bn.weight
freezing model.9.cv2.0.cv2.bn.bias
freezing model.9.cv2.0.cv3.conv.weight
freezing model.9.cv2.0.cv3.bn.weight
freezing model.9.cv2.0.cv3.bn.bias
freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.9.cv2.0.m.0.cv2.conv.weight
freezing model.9.cv2.0.m.0.cv2.bn.weight
freezing model.9.cv2.0.m.0.cv2.bn.bias
freezing model.9.cv2.1.conv.weight
freezing model.9.cv2.1.bn.weight
freezing model.9.cv2.1.bn.bias
freezing model.9.cv3.0.cv1.conv.weight
freezing model.9.cv3.0.cv1.bn.weight
freezing model.9.cv3.0.cv1.bn.bias
freezing model.9.cv3.0.cv2.conv.weight
freezing model.9.cv3.0.cv2.bn.weight
freezing model.9.cv3.0.cv2.bn.bias
freezing model.9.cv3.0.cv3.conv.weight
freezing model.9.cv3.0.cv3.bn.weight
freezing model.9.cv3.0.cv3.bn.bias
freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.9.cv3.0.m.0.cv2.conv.weight
freezing model.9.cv3.0.m.0.cv2.bn.weight
freezing model.9.cv3.0.m.0.cv2.bn.bias
freezing model.9.cv3.1.conv.weight
freezing model.9.cv3.1.bn.weight
freezing model.9.cv3.1.bn.bias
freezing model.9.cv4.conv.weight
freezing model.9.cv4.bn.weight
freezing model.9.cv4.bn.bias
[34m[1moptimizer:[39m[22m SGD(lr=0.003) with parameter groups 238 weight(decay=0.0), 255 weight(decay=0.0005), 253 bias
[34m[1malbumentations: [39m[22mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))
[34m[1mtrain: [39m[22mScanning /home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/SailbotVT-3/train/labels.cache... 8130 images, 0 backgrounds, 0
[34m[1mval: [39m[22mScanning /home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/SailbotVT-3/valid/labels.cache... 765 images, 0 backgrounds, 0 co
Plotting labels to runs/train/exp50/labels.jpg...
Image sizes 640 train, 640 val
Using 4 dataloader workers
Logging results to [1mruns/train/exp50
Starting training for 4 epochs...
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
  0%|          | 0/2033 00:00
Traceback (most recent call last):
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 644, in <module>
    main(opt)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 538, in main
    train(opt.hyp, opt, device, callbacks)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 314, in train
    pred = model(imgs)  # forward
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/models/yolo.py", line 633, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/models/yolo.py", line 533, in _forward_once
    x = m(x)  # run
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/models/common.py", line 54, in forward
    return self.act(self.bn(self.conv(x)))
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 644, in <module>
    main(opt)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 538, in main
    train(opt.hyp, opt, device, callbacks)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 314, in train
    pred = model(imgs)  # forward
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/models/yolo.py", line 633, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/models/yolo.py", line 533, in _forward_once
    x = m(x)  # run
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/models/common.py", line 54, in forward
    return self.act(self.bn(self.conv(x)))
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/animated/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt