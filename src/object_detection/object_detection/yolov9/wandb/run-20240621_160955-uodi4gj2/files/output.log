Overriding model.yaml nc=80 with nc=1
                 from  n    params  module                                  arguments
  0                -1  1         0  models.common.Silence                   []
  1                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]
  2                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
  3                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]
  4                -1  1    164352  models.common.ADown                     [256, 256]
  5                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]
  6                -1  1    656384  models.common.ADown                     [512, 512]
  7                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]
  8                -1  1    656384  models.common.ADown                     [512, 512]
  9                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]
 10                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 12           [-1, 7]  1         0  models.common.Concat                    [1]
 13                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]
 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 15           [-1, 5]  1         0  models.common.Concat                    [1]
 16                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]
 17                -1  1    164352  models.common.ADown                     [256, 256]
 18          [-1, 13]  1         0  models.common.Concat                    [1]
 19                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]
 20                -1  1    656384  models.common.ADown                     [512, 512]
 21          [-1, 10]  1         0  models.common.Concat                    [1]
 22                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]
 23                 5  1    131328  models.common.CBLinear                  [512, [256]]
 24                 7  1    393984  models.common.CBLinear                  [512, [256, 512]]
 25                 9  1    656640  models.common.CBLinear                  [512, [256, 512, 512]]
 26                 0  1      1856  models.common.Conv                      [3, 64, 3, 2]
 27                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]
 28                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]
 29                -1  1    164352  models.common.ADown                     [256, 256]
 30  [23, 24, 25, -1]  1         0  models.common.CBFuse                    [[0, 0, 0]]
 31                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]
 32                -1  1    656384  models.common.ADown                     [512, 512]
 33      [24, 25, -1]  1         0  models.common.CBFuse                    [[1, 1]]
 34                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]
 35                -1  1    656384  models.common.ADown                     [512, 512]
 36          [25, -1]  1         0  models.common.CBFuse                    [[2]]
 37                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]
 38[31, 34, 37, 16, 19, 22]  1  21542822  models.yolo.DualDDetect                 [1, [512, 512, 512, 256, 512, 512]]
yolov9-c summary: 962 layers, 50999590 parameters, 50999558 gradients, 238.9 GFLOPs
Transferred 1448/1460 items from weights/yolov9-c.pt
[34m[1mAMP: [39m[22mchecks passed ✅
freezing model.1.conv.weight
freezing model.1.bn.weight
freezing model.1.bn.bias
freezing model.2.conv.weight
freezing model.2.bn.weight
freezing model.2.bn.bias
freezing model.3.cv1.conv.weight
freezing model.3.cv1.bn.weight
freezing model.3.cv1.bn.bias
freezing model.3.cv2.0.cv1.conv.weight
freezing model.3.cv2.0.cv1.bn.weight
freezing model.3.cv2.0.cv1.bn.bias
freezing model.3.cv2.0.cv2.conv.weight
freezing model.3.cv2.0.cv2.bn.weight
freezing model.3.cv2.0.cv2.bn.bias
freezing model.3.cv2.0.cv3.conv.weight
freezing model.3.cv2.0.cv3.bn.weight
freezing model.3.cv2.0.cv3.bn.bias
freezing model.3.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.3.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.3.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.3.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.3.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.3.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.3.cv2.0.m.0.cv2.conv.weight
freezing model.3.cv2.0.m.0.cv2.bn.weight
freezing model.3.cv2.0.m.0.cv2.bn.bias
freezing model.3.cv2.1.conv.weight
freezing model.3.cv2.1.bn.weight
freezing model.3.cv2.1.bn.bias
freezing model.3.cv3.0.cv1.conv.weight
freezing model.3.cv3.0.cv1.bn.weight
freezing model.3.cv3.0.cv1.bn.bias
freezing model.3.cv3.0.cv2.conv.weight
freezing model.3.cv3.0.cv2.bn.weight
freezing model.3.cv3.0.cv2.bn.bias
freezing model.3.cv3.0.cv3.conv.weight
freezing model.3.cv3.0.cv3.bn.weight
freezing model.3.cv3.0.cv3.bn.bias
freezing model.3.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.3.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.3.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.3.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.3.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.3.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.3.cv3.0.m.0.cv2.conv.weight
freezing model.3.cv3.0.m.0.cv2.bn.weight
freezing model.3.cv3.0.m.0.cv2.bn.bias
freezing model.3.cv3.1.conv.weight
freezing model.3.cv3.1.bn.weight
freezing model.3.cv3.1.bn.bias
freezing model.3.cv4.conv.weight
freezing model.3.cv4.bn.weight
freezing model.3.cv4.bn.bias
freezing model.4.cv1.conv.weight
freezing model.4.cv1.bn.weight
freezing model.4.cv1.bn.bias
freezing model.4.cv2.conv.weight
freezing model.4.cv2.bn.weight
freezing model.4.cv2.bn.bias
freezing model.5.cv1.conv.weight
freezing model.5.cv1.bn.weight
freezing model.5.cv1.bn.bias
freezing model.5.cv2.0.cv1.conv.weight
freezing model.5.cv2.0.cv1.bn.weight
freezing model.5.cv2.0.cv1.bn.bias
freezing model.5.cv2.0.cv2.conv.weight
freezing model.5.cv2.0.cv2.bn.weight
freezing model.5.cv2.0.cv2.bn.bias
freezing model.5.cv2.0.cv3.conv.weight
freezing model.5.cv2.0.cv3.bn.weight
freezing model.5.cv2.0.cv3.bn.bias
freezing model.5.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.5.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.5.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.5.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.5.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.5.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.5.cv2.0.m.0.cv2.conv.weight
freezing model.5.cv2.0.m.0.cv2.bn.weight
freezing model.5.cv2.0.m.0.cv2.bn.bias
freezing model.5.cv2.1.conv.weight
freezing model.5.cv2.1.bn.weight
freezing model.5.cv2.1.bn.bias
freezing model.5.cv3.0.cv1.conv.weight
freezing model.5.cv3.0.cv1.bn.weight
freezing model.5.cv3.0.cv1.bn.bias
freezing model.5.cv3.0.cv2.conv.weight
freezing model.5.cv3.0.cv2.bn.weight
freezing model.5.cv3.0.cv2.bn.bias
freezing model.5.cv3.0.cv3.conv.weight
freezing model.5.cv3.0.cv3.bn.weight
freezing model.5.cv3.0.cv3.bn.bias
freezing model.5.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.5.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.5.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.5.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.5.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.5.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.5.cv3.0.m.0.cv2.conv.weight
freezing model.5.cv3.0.m.0.cv2.bn.weight
freezing model.5.cv3.0.m.0.cv2.bn.bias
freezing model.5.cv3.1.conv.weight
freezing model.5.cv3.1.bn.weight
freezing model.5.cv3.1.bn.bias
freezing model.5.cv4.conv.weight
freezing model.5.cv4.bn.weight
freezing model.5.cv4.bn.bias
freezing model.6.cv1.conv.weight
freezing model.6.cv1.bn.weight
freezing model.6.cv1.bn.bias
freezing model.6.cv2.conv.weight
freezing model.6.cv2.bn.weight
freezing model.6.cv2.bn.bias
freezing model.7.cv1.conv.weight
freezing model.7.cv1.bn.weight
freezing model.7.cv1.bn.bias
freezing model.7.cv2.0.cv1.conv.weight
freezing model.7.cv2.0.cv1.bn.weight
freezing model.7.cv2.0.cv1.bn.bias
freezing model.7.cv2.0.cv2.conv.weight
freezing model.7.cv2.0.cv2.bn.weight
freezing model.7.cv2.0.cv2.bn.bias
freezing model.7.cv2.0.cv3.conv.weight
freezing model.7.cv2.0.cv3.bn.weight
freezing model.7.cv2.0.cv3.bn.bias
freezing model.7.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.7.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.7.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.7.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.7.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.7.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.7.cv2.0.m.0.cv2.conv.weight
freezing model.7.cv2.0.m.0.cv2.bn.weight
freezing model.7.cv2.0.m.0.cv2.bn.bias
freezing model.7.cv2.1.conv.weight
freezing model.7.cv2.1.bn.weight
freezing model.7.cv2.1.bn.bias
freezing model.7.cv3.0.cv1.conv.weight
freezing model.7.cv3.0.cv1.bn.weight
freezing model.7.cv3.0.cv1.bn.bias
freezing model.7.cv3.0.cv2.conv.weight
freezing model.7.cv3.0.cv2.bn.weight
freezing model.7.cv3.0.cv2.bn.bias
freezing model.7.cv3.0.cv3.conv.weight
freezing model.7.cv3.0.cv3.bn.weight
freezing model.7.cv3.0.cv3.bn.bias
freezing model.7.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.7.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.7.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.7.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.7.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.7.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.7.cv3.0.m.0.cv2.conv.weight
freezing model.7.cv3.0.m.0.cv2.bn.weight
freezing model.7.cv3.0.m.0.cv2.bn.bias
freezing model.7.cv3.1.conv.weight
freezing model.7.cv3.1.bn.weight
freezing model.7.cv3.1.bn.bias
freezing model.7.cv4.conv.weight
freezing model.7.cv4.bn.weight
freezing model.7.cv4.bn.bias
freezing model.8.cv1.conv.weight
freezing model.8.cv1.bn.weight
freezing model.8.cv1.bn.bias
freezing model.8.cv2.conv.weight
freezing model.8.cv2.bn.weight
freezing model.8.cv2.bn.bias
freezing model.9.cv1.conv.weight
freezing model.9.cv1.bn.weight
freezing model.9.cv1.bn.bias
freezing model.9.cv2.0.cv1.conv.weight
freezing model.9.cv2.0.cv1.bn.weight
freezing model.9.cv2.0.cv1.bn.bias
freezing model.9.cv2.0.cv2.conv.weight
freezing model.9.cv2.0.cv2.bn.weight
freezing model.9.cv2.0.cv2.bn.bias
freezing model.9.cv2.0.cv3.conv.weight
freezing model.9.cv2.0.cv3.bn.weight
freezing model.9.cv2.0.cv3.bn.bias
freezing model.9.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.9.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.9.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.9.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.9.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.9.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.9.cv2.0.m.0.cv2.conv.weight
freezing model.9.cv2.0.m.0.cv2.bn.weight
freezing model.9.cv2.0.m.0.cv2.bn.bias
freezing model.9.cv2.1.conv.weight
freezing model.9.cv2.1.bn.weight
freezing model.9.cv2.1.bn.bias
freezing model.9.cv3.0.cv1.conv.weight
freezing model.9.cv3.0.cv1.bn.weight
freezing model.9.cv3.0.cv1.bn.bias
freezing model.9.cv3.0.cv2.conv.weight
freezing model.9.cv3.0.cv2.bn.weight
freezing model.9.cv3.0.cv2.bn.bias
freezing model.9.cv3.0.cv3.conv.weight
freezing model.9.cv3.0.cv3.bn.weight
freezing model.9.cv3.0.cv3.bn.bias
freezing model.9.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.9.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.9.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.9.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.9.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.9.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.9.cv3.0.m.0.cv2.conv.weight
freezing model.9.cv3.0.m.0.cv2.bn.weight
freezing model.9.cv3.0.m.0.cv2.bn.bias
freezing model.9.cv3.1.conv.weight
freezing model.9.cv3.1.bn.weight
freezing model.9.cv3.1.bn.bias
freezing model.9.cv4.conv.weight
freezing model.9.cv4.bn.weight
freezing model.9.cv4.bn.bias
freezing model.10.cv1.conv.weight
freezing model.10.cv1.bn.weight
freezing model.10.cv1.bn.bias
freezing model.10.cv5.conv.weight
freezing model.10.cv5.bn.weight
freezing model.10.cv5.bn.bias
freezing model.13.cv1.conv.weight
freezing model.13.cv1.bn.weight
freezing model.13.cv1.bn.bias
freezing model.13.cv2.0.cv1.conv.weight
freezing model.13.cv2.0.cv1.bn.weight
freezing model.13.cv2.0.cv1.bn.bias
freezing model.13.cv2.0.cv2.conv.weight
freezing model.13.cv2.0.cv2.bn.weight
freezing model.13.cv2.0.cv2.bn.bias
freezing model.13.cv2.0.cv3.conv.weight
freezing model.13.cv2.0.cv3.bn.weight
freezing model.13.cv2.0.cv3.bn.bias
freezing model.13.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.13.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.13.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.13.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.13.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.13.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.13.cv2.0.m.0.cv2.conv.weight
freezing model.13.cv2.0.m.0.cv2.bn.weight
freezing model.13.cv2.0.m.0.cv2.bn.bias
freezing model.13.cv2.1.conv.weight
freezing model.13.cv2.1.bn.weight
freezing model.13.cv2.1.bn.bias
freezing model.13.cv3.0.cv1.conv.weight
freezing model.13.cv3.0.cv1.bn.weight
freezing model.13.cv3.0.cv1.bn.bias
freezing model.13.cv3.0.cv2.conv.weight
freezing model.13.cv3.0.cv2.bn.weight
freezing model.13.cv3.0.cv2.bn.bias
freezing model.13.cv3.0.cv3.conv.weight
freezing model.13.cv3.0.cv3.bn.weight
freezing model.13.cv3.0.cv3.bn.bias
freezing model.13.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.13.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.13.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.13.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.13.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.13.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.13.cv3.0.m.0.cv2.conv.weight
freezing model.13.cv3.0.m.0.cv2.bn.weight
freezing model.13.cv3.0.m.0.cv2.bn.bias
freezing model.13.cv3.1.conv.weight
freezing model.13.cv3.1.bn.weight
freezing model.13.cv3.1.bn.bias
freezing model.13.cv4.conv.weight
freezing model.13.cv4.bn.weight
freezing model.13.cv4.bn.bias
freezing model.16.cv1.conv.weight
freezing model.16.cv1.bn.weight
freezing model.16.cv1.bn.bias
freezing model.16.cv2.0.cv1.conv.weight
freezing model.16.cv2.0.cv1.bn.weight
freezing model.16.cv2.0.cv1.bn.bias
freezing model.16.cv2.0.cv2.conv.weight
freezing model.16.cv2.0.cv2.bn.weight
freezing model.16.cv2.0.cv2.bn.bias
freezing model.16.cv2.0.cv3.conv.weight
freezing model.16.cv2.0.cv3.bn.weight
freezing model.16.cv2.0.cv3.bn.bias
freezing model.16.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.16.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.16.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.16.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.16.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.16.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.16.cv2.0.m.0.cv2.conv.weight
freezing model.16.cv2.0.m.0.cv2.bn.weight
freezing model.16.cv2.0.m.0.cv2.bn.bias
freezing model.16.cv2.1.conv.weight
freezing model.16.cv2.1.bn.weight
freezing model.16.cv2.1.bn.bias
freezing model.16.cv3.0.cv1.conv.weight
freezing model.16.cv3.0.cv1.bn.weight
freezing model.16.cv3.0.cv1.bn.bias
freezing model.16.cv3.0.cv2.conv.weight
freezing model.16.cv3.0.cv2.bn.weight
freezing model.16.cv3.0.cv2.bn.bias
freezing model.16.cv3.0.cv3.conv.weight
freezing model.16.cv3.0.cv3.bn.weight
freezing model.16.cv3.0.cv3.bn.bias
freezing model.16.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.16.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.16.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.16.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.16.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.16.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.16.cv3.0.m.0.cv2.conv.weight
freezing model.16.cv3.0.m.0.cv2.bn.weight
freezing model.16.cv3.0.m.0.cv2.bn.bias
freezing model.16.cv3.1.conv.weight
freezing model.16.cv3.1.bn.weight
freezing model.16.cv3.1.bn.bias
freezing model.16.cv4.conv.weight
freezing model.16.cv4.bn.weight
freezing model.16.cv4.bn.bias
freezing model.17.cv1.conv.weight
freezing model.17.cv1.bn.weight
freezing model.17.cv1.bn.bias
freezing model.17.cv2.conv.weight
freezing model.17.cv2.bn.weight
freezing model.17.cv2.bn.bias
freezing model.19.cv1.conv.weight
freezing model.19.cv1.bn.weight
freezing model.19.cv1.bn.bias
freezing model.19.cv2.0.cv1.conv.weight
freezing model.19.cv2.0.cv1.bn.weight
freezing model.19.cv2.0.cv1.bn.bias
freezing model.19.cv2.0.cv2.conv.weight
freezing model.19.cv2.0.cv2.bn.weight
freezing model.19.cv2.0.cv2.bn.bias
freezing model.19.cv2.0.cv3.conv.weight
freezing model.19.cv2.0.cv3.bn.weight
freezing model.19.cv2.0.cv3.bn.bias
freezing model.19.cv2.0.m.0.cv1.conv1.conv.weight
freezing model.19.cv2.0.m.0.cv1.conv1.bn.weight
freezing model.19.cv2.0.m.0.cv1.conv1.bn.bias
freezing model.19.cv2.0.m.0.cv1.conv2.conv.weight
freezing model.19.cv2.0.m.0.cv1.conv2.bn.weight
freezing model.19.cv2.0.m.0.cv1.conv2.bn.bias
freezing model.19.cv2.0.m.0.cv2.conv.weight
freezing model.19.cv2.0.m.0.cv2.bn.weight
freezing model.19.cv2.0.m.0.cv2.bn.bias
freezing model.19.cv2.1.conv.weight
freezing model.19.cv2.1.bn.weight
freezing model.19.cv2.1.bn.bias
freezing model.19.cv3.0.cv1.conv.weight
freezing model.19.cv3.0.cv1.bn.weight
freezing model.19.cv3.0.cv1.bn.bias
freezing model.19.cv3.0.cv2.conv.weight
freezing model.19.cv3.0.cv2.bn.weight
freezing model.19.cv3.0.cv2.bn.bias
freezing model.19.cv3.0.cv3.conv.weight
freezing model.19.cv3.0.cv3.bn.weight
freezing model.19.cv3.0.cv3.bn.bias
freezing model.19.cv3.0.m.0.cv1.conv1.conv.weight
freezing model.19.cv3.0.m.0.cv1.conv1.bn.weight
freezing model.19.cv3.0.m.0.cv1.conv1.bn.bias
freezing model.19.cv3.0.m.0.cv1.conv2.conv.weight
freezing model.19.cv3.0.m.0.cv1.conv2.bn.weight
freezing model.19.cv3.0.m.0.cv1.conv2.bn.bias
freezing model.19.cv3.0.m.0.cv2.conv.weight
freezing model.19.cv3.0.m.0.cv2.bn.weight
freezing model.19.cv3.0.m.0.cv2.bn.bias
freezing model.19.cv3.1.conv.weight
freezing model.19.cv3.1.bn.weight
freezing model.19.cv3.1.bn.bias
freezing model.19.cv4.conv.weight
freezing model.19.cv4.bn.weight
freezing model.19.cv4.bn.bias
[34m[1moptimizer:[39m[22m SGD(lr=0.003) with parameter groups 238 weight(decay=0.0), 255 weight(decay=0.0005), 253 bias
[34m[1malbumentations: [39m[22mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))
[34m[1mtrain: [39m[22mScanning /home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/SailbotVT-3/train/labels.ca
[34m[1mval: [39m[22mScanning /home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/SailbotVT-3/valid/labels.cach
Plotting labels to runs/train/exp46/labels.jpg...
Image sizes 640 train, 640 val
Using 4 dataloader workers
Logging results to [1mruns/train/exp46
Starting training for 4 epochs...
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
        0/3      2.77G      3.141      8.887      2.418          4        640:   0%|          | 0/2033 00:02Exception in thread Thread-8 (plot_images):
Traceback (most recent call last):
  File "/home/animated/miniforge3/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/home/animated/miniforge3/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/utils/plots.py", line 300, in plot_images
    annotator.box_label(box, label, color=color)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/utils/plots.py", line 86, in box_label
    w, h = self.font.getsize(label)  # text width, height
AttributeError: 'FreeTypeFont' object has no attribute 'getsize'
WARNING ⚠️ TensorBoard graph visualization failure Only tensors, lists, tuples of tensors, or dictionary of tensors can be output from traced functions
        0/3      2.77G      3.477      8.861      2.665          4        640:   0%|          | 2/2033 00:03Exception in thread Thread-9 (plot_images):
Traceback (most recent call last):
  File "/home/animated/miniforge3/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/home/animated/miniforge3/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/utils/plots.py", line 300, in plot_images
    annotator.box_label(box, label, color=color)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/utils/plots.py", line 86, in box_label
    w, h = self.font.getsize(label)  # text width, height
AttributeError: 'FreeTypeFont' object has no attribute 'getsize'
        0/3      2.78G      3.142      9.495      2.433          4        640:   0%|          | 3/2033 00:04Exception in thread Thread-10 (plot_images):
Traceback (most recent call last):
  File "/home/animated/miniforge3/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/home/animated/miniforge3/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/utils/plots.py", line 300, in plot_images
    annotator.box_label(box, label, color=color)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/utils/plots.py", line 86, in box_label
    w, h = self.font.getsize(label)  # text width, height
AttributeError: 'FreeTypeFont' object has no attribute 'getsize'

























































































































































































































        0/3       3.1G       2.47      1.879      2.187          2        640: 100%|██████████| 2033/2033 07:20











                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 96/96 00:23
                   all        765        765      0.788      0.708      0.777      0.397
      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size




















































































































        1/3      3.27G      2.281      1.273      2.073          4        640:  54%|█████▍    | 1105/2033 03:53
Traceback (most recent call last):
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 644, in <module>
    main(opt)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 538, in main
    train(opt.hyp, opt, device, callbacks)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 322, in train
    scaler.scale(loss).backward()
  File "/home/animated/.local/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/animated/.local/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/animated/.local/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 644, in <module>
    main(opt)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 538, in main
    train(opt.hyp, opt, device, callbacks)
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/yolov9/train_dual.py", line 322, in train
    scaler.scale(loss).backward()
  File "/home/animated/.local/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/animated/.local/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/animated/.local/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt