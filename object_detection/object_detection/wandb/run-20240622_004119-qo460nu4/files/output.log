Freezing layer 'model.0.conv.weight'
Freezing layer 'model.0.bn.weight'
Freezing layer 'model.0.bn.bias'
Freezing layer 'model.1.conv.weight'
Freezing layer 'model.1.bn.weight'
Freezing layer 'model.1.bn.bias'
Freezing layer 'model.2.cv1.conv.weight'
Freezing layer 'model.2.cv1.bn.weight'
Freezing layer 'model.2.cv1.bn.bias'
Freezing layer 'model.2.cv2.conv.weight'
Freezing layer 'model.2.cv2.bn.weight'
Freezing layer 'model.2.cv2.bn.bias'
Freezing layer 'model.2.m.0.cv1.conv.weight'
Freezing layer 'model.2.m.0.cv1.bn.weight'
Freezing layer 'model.2.m.0.cv1.bn.bias'
Freezing layer 'model.2.m.0.cv2.conv.weight'
Freezing layer 'model.2.m.0.cv2.bn.weight'
Freezing layer 'model.2.m.0.cv2.bn.bias'
Freezing layer 'model.2.m.1.cv1.conv.weight'
Freezing layer 'model.2.m.1.cv1.bn.weight'
Freezing layer 'model.2.m.1.cv1.bn.bias'
Freezing layer 'model.2.m.1.cv2.conv.weight'
Freezing layer 'model.2.m.1.cv2.bn.weight'
Freezing layer 'model.2.m.1.cv2.bn.bias'
Freezing layer 'model.3.conv.weight'
Freezing layer 'model.3.bn.weight'
Freezing layer 'model.3.bn.bias'
Freezing layer 'model.4.cv1.conv.weight'
Freezing layer 'model.4.cv1.bn.weight'
Freezing layer 'model.4.cv1.bn.bias'
Freezing layer 'model.4.cv2.conv.weight'
Freezing layer 'model.4.cv2.bn.weight'
Freezing layer 'model.4.cv2.bn.bias'
Freezing layer 'model.4.m.0.cv1.conv.weight'
Freezing layer 'model.4.m.0.cv1.bn.weight'
Freezing layer 'model.4.m.0.cv1.bn.bias'
Freezing layer 'model.4.m.0.cv2.conv.weight'
Freezing layer 'model.4.m.0.cv2.bn.weight'
Freezing layer 'model.4.m.0.cv2.bn.bias'
Freezing layer 'model.4.m.1.cv1.conv.weight'
Freezing layer 'model.4.m.1.cv1.bn.weight'
Freezing layer 'model.4.m.1.cv1.bn.bias'
Freezing layer 'model.4.m.1.cv2.conv.weight'
Freezing layer 'model.4.m.1.cv2.bn.weight'
Freezing layer 'model.4.m.1.cv2.bn.bias'
Freezing layer 'model.4.m.2.cv1.conv.weight'
Freezing layer 'model.4.m.2.cv1.bn.weight'
Freezing layer 'model.4.m.2.cv1.bn.bias'
Freezing layer 'model.4.m.2.cv2.conv.weight'
Freezing layer 'model.4.m.2.cv2.bn.weight'
Freezing layer 'model.4.m.2.cv2.bn.bias'
Freezing layer 'model.4.m.3.cv1.conv.weight'
Freezing layer 'model.4.m.3.cv1.bn.weight'
Freezing layer 'model.4.m.3.cv1.bn.bias'
Freezing layer 'model.4.m.3.cv2.conv.weight'
Freezing layer 'model.4.m.3.cv2.bn.weight'
Freezing layer 'model.4.m.3.cv2.bn.bias'
Freezing layer 'model.5.cv1.conv.weight'
Freezing layer 'model.5.cv1.bn.weight'
Freezing layer 'model.5.cv1.bn.bias'
Freezing layer 'model.5.cv2.conv.weight'
Freezing layer 'model.5.cv2.bn.weight'
Freezing layer 'model.5.cv2.bn.bias'
Freezing layer 'model.6.cv1.conv.weight'
Freezing layer 'model.6.cv1.bn.weight'
Freezing layer 'model.6.cv1.bn.bias'
Freezing layer 'model.6.cv2.conv.weight'
Freezing layer 'model.6.cv2.bn.weight'
Freezing layer 'model.6.cv2.bn.bias'
Freezing layer 'model.6.m.0.cv1.conv.weight'
Freezing layer 'model.6.m.0.cv1.bn.weight'
Freezing layer 'model.6.m.0.cv1.bn.bias'
Freezing layer 'model.6.m.0.cv2.conv.weight'
Freezing layer 'model.6.m.0.cv2.bn.weight'
Freezing layer 'model.6.m.0.cv2.bn.bias'
Freezing layer 'model.6.m.1.cv1.conv.weight'
Freezing layer 'model.6.m.1.cv1.bn.weight'
Freezing layer 'model.6.m.1.cv1.bn.bias'
Freezing layer 'model.6.m.1.cv2.conv.weight'
Freezing layer 'model.6.m.1.cv2.bn.weight'
Freezing layer 'model.6.m.1.cv2.bn.bias'
Freezing layer 'model.6.m.2.cv1.conv.weight'
Freezing layer 'model.6.m.2.cv1.bn.weight'
Freezing layer 'model.6.m.2.cv1.bn.bias'
Freezing layer 'model.6.m.2.cv2.conv.weight'
Freezing layer 'model.6.m.2.cv2.bn.weight'
Freezing layer 'model.6.m.2.cv2.bn.bias'
Freezing layer 'model.6.m.3.cv1.conv.weight'
Freezing layer 'model.6.m.3.cv1.bn.weight'
Freezing layer 'model.6.m.3.cv1.bn.bias'
Freezing layer 'model.6.m.3.cv2.conv.weight'
Freezing layer 'model.6.m.3.cv2.bn.weight'
Freezing layer 'model.6.m.3.cv2.bn.bias'
Freezing layer 'model.7.cv1.conv.weight'
Freezing layer 'model.7.cv1.bn.weight'
Freezing layer 'model.7.cv1.bn.bias'
Freezing layer 'model.7.cv2.conv.weight'
Freezing layer 'model.7.cv2.bn.weight'
Freezing layer 'model.7.cv2.bn.bias'
Freezing layer 'model.8.cv1.conv.weight'
Freezing layer 'model.8.cv1.bn.weight'
Freezing layer 'model.8.cv1.bn.bias'
Freezing layer 'model.8.cv2.conv.weight'
Freezing layer 'model.8.cv2.bn.weight'
Freezing layer 'model.8.cv2.bn.bias'
Freezing layer 'model.8.m.0.cv1.0.conv.weight'
Freezing layer 'model.8.m.0.cv1.0.bn.weight'
Freezing layer 'model.8.m.0.cv1.0.bn.bias'
Freezing layer 'model.8.m.0.cv1.1.conv.weight'
Freezing layer 'model.8.m.0.cv1.1.bn.weight'
Freezing layer 'model.8.m.0.cv1.1.bn.bias'
Freezing layer 'model.8.m.0.cv1.2.conv.weight'
Freezing layer 'model.8.m.0.cv1.2.bn.weight'
Freezing layer 'model.8.m.0.cv1.2.bn.bias'
Freezing layer 'model.8.m.0.cv1.3.conv.weight'
Freezing layer 'model.8.m.0.cv1.3.bn.weight'
Freezing layer 'model.8.m.0.cv1.3.bn.bias'
Freezing layer 'model.8.m.0.cv1.4.conv.weight'
Freezing layer 'model.8.m.0.cv1.4.bn.weight'
Freezing layer 'model.8.m.0.cv1.4.bn.bias'
Freezing layer 'model.8.m.1.cv1.0.conv.weight'
Freezing layer 'model.8.m.1.cv1.0.bn.weight'
Freezing layer 'model.8.m.1.cv1.0.bn.bias'
Freezing layer 'model.8.m.1.cv1.1.conv.weight'
Freezing layer 'model.8.m.1.cv1.1.bn.weight'
Freezing layer 'model.8.m.1.cv1.1.bn.bias'
Freezing layer 'model.8.m.1.cv1.2.conv.weight'
Freezing layer 'model.8.m.1.cv1.2.bn.weight'
Freezing layer 'model.8.m.1.cv1.2.bn.bias'
Freezing layer 'model.8.m.1.cv1.3.conv.weight'
Freezing layer 'model.8.m.1.cv1.3.bn.weight'
Freezing layer 'model.8.m.1.cv1.3.bn.bias'
Freezing layer 'model.8.m.1.cv1.4.conv.weight'
Freezing layer 'model.8.m.1.cv1.4.bn.weight'
Freezing layer 'model.8.m.1.cv1.4.bn.bias'
Freezing layer 'model.9.cv1.conv.weight'
Freezing layer 'model.9.cv1.bn.weight'
Freezing layer 'model.9.cv1.bn.bias'
Freezing layer 'model.9.cv2.conv.weight'
Freezing layer 'model.9.cv2.bn.weight'
Freezing layer 'model.9.cv2.bn.bias'
Freezing layer 'model.23.dfl.conv.weight'
[34m[1mAMP: [39m[22mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...
[34m[1mAMP: [39m[22mchecks passed âœ…
[34m[1malbumentations: [39m[22mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))
[34m[1mtrain: [39m[22mScanning /home/animated/Projects/Sailbot/src/object_detection/object_detection/datasets/SailbotVT-4/train/labels.cache... 12816 images, 1474 backgrou
[34m[1mval: [39m[22mScanning /home/animated/Projects/Sailbot/src/object_detection/object_detection/datasets/SailbotVT-4/valid/labels.cache... 1845 images, 211 backgrounds,
Plotting labels to runs/detect/train34/labels.jpg...
[34m[1moptimizer:[39m[22m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically...
[34m[1moptimizer:[39m[22m AdamW(lr=0.002, momentum=0.9) with parameter groups 135 weight(decay=0.0), 148 weight(decay=0.0005), 147 bias(decay=0.0)
  0%|          | 0/3204 [00:00<?, ?it/s]
[34m[1mTensorBoard: [39m[22mmodel graph visualization added âœ…
Image sizes 640 train, 640 val
Using 8 dataloader workers
Logging results to [1mruns/detect/train34
Starting training for 4 epochs...

























        1/4      2.12G      1.408      1.375      1.379      1.562      1.853      1.342          6        640:  10%|â–‰         | 319/3204 [00:52<07:53,  6.1
Traceback (most recent call last):
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/train_buoy_classifier.py", line 4, in <module>
    model.train(
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/engine/model.py", line 657, in train
    self.trainer.train()
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/engine/trainer.py", line 213, in train
    self._do_train(world_size)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/engine/trainer.py", line 381, in _do_train
    self.loss, self.loss_items = self.model(batch)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/nn/tasks.py", line 93, in forward
    return self.loss(x, *args, **kwargs)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/nn/tasks.py", line 275, in loss
    return self.criterion(preds, batch)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/utils/loss.py", line 724, in __call__
    loss_one2many = self.one2many(one2many, batch)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/utils/loss.py", line 209, in __call__
    imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size (h,w)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/animated/Projects/Sailbot/src/object_detection/object_detection/train_buoy_classifier.py", line 4, in <module>
    model.train(
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/engine/model.py", line 657, in train
    self.trainer.train()
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/engine/trainer.py", line 213, in train
    self._do_train(world_size)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/engine/trainer.py", line 381, in _do_train
    self.loss, self.loss_items = self.model(batch)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/nn/tasks.py", line 93, in forward
    return self.loss(x, *args, **kwargs)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/nn/tasks.py", line 275, in loss
    return self.criterion(preds, batch)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/utils/loss.py", line 724, in __call__
    loss_one2many = self.one2many(one2many, batch)
  File "/home/animated/miniforge3/lib/python3.10/site-packages/ultralytics/utils/loss.py", line 209, in __call__
    imgsz = torch.tensor(feats[0].shape[2:], device=self.device, dtype=dtype) * self.stride[0]  # image size (h,w)
KeyboardInterrupt